##机器学习中的关键组件
- 数据 data
- 模型 model
- 目标函数 objective function，用来量化模型的有效性
- 算法 algorithm，调整模型参数以优化目标函数

###数据
数据集由一个个样本（example, sample）组成，大多时候，它们遵循独立同分布(independently and identically distributed, i.i.d.)。 
样本有时也叫做数据点（data point）或者数据实例（data instance），通常每个样本由一组称为特征（features，或协变量（covariates））的属性组成。
机器学习模型会根据这些属性进行预测。 在监督学习问题中，模型要预测的是一个特殊的属性，它被称为标签（label，或目标（target））。

###模型
模型是AI学习者都了解的，但是深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，
因此被称为深度学习（deep learning）

###目标函数
在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为目标函数（objective function）。
我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为损失函数（loss function，或cost function）。

通常，损失函数是根据模型参数定义的，并取决于数据集。 在一个数据集上，我们可以通过最小化总损失来学习模型参数的最佳值。 该数据集由一些为训练而
收集的样本组成，称为训练数据集（training dataset，或称为训练集（training set））。 然而，在训练数据上表现良好的模型， 并不一定在“新数据
集”上有同样的性能，这里的“新数据集”通常称为测试数据集（test dataset，或称为测试集（test set））。

综上所述，可用数据集通常可以分成两部分：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。 然后我们观察模型在这两部分数据集的性能。
“一个模型在训练数据集上的性能”可以被想象成“一个学生在模拟考试中的分数”。 这个分数用来为一些真正的期末考试做参考，即使成绩令人鼓舞， 也不能保证
期末考试成功。 换言之，测试性能可能会显著偏离训练性能。 当一个模型在训练集上表现良好，但不能推广到测试集时， 这个模型被称为过拟合（overfitting）的。

###优化算法
当我们获得了一些数据源及其表示、一个模型和一个合适的损失函数，接下来就需要一种算法，它能够搜索出最佳参数，以最小化损失函数。 深度学习中，大多
流行的优化算法通常基于一种基本方法–梯度下降（gradient descent）。 简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进
行少量变动，训练集损失会朝哪个方向移动。 然后，它在可以减少损失的方向上优化参数。

##监督学习
监督学习（supervised learning）擅长在“给定输入特征”的情况下预测标签。 每个“特征-标签”对都称为一个样本（example）。 有时，即使标签是未知的，
样本也可以指代输入特征。 我们的目标是生成一个模型，能够将任何输入特征映射到标签（即预测）。

监督学习的学习过程一般可以分为三大步骤：
1. 从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。有时，这些样本已有标签（例如，患者是否在下一年内康复？）；有时，这些样本可能
需要被人工标记（例如，图像分类）。这些输入和相应的标签一起构成了训练数据集；
2. 选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；
3. 将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测。

### 回归
回归（regression）是最简单的监督学习任务之一。 假设有一组房屋销售数据表格，其中每行对应一个房子，每列对应一个相关的属性，例如房屋的面积、
卧室的数量、浴室的数量以及到镇中心的步行距离，等等。 每一行的属性构成了一个房子样本的特征向量。为什么这个任务可以归类为回归问题呢？本质上是输
出决定的。 销售价格（即标签）是一个数值。 当标签取任意数值时，我们称之为回归问题，此时的目标是生成一个模型，使它的预测非常接近实际标签值。总而
言之，判断回归问题的一个很好的经验法则是，任何有关“有多少”的问题很可能就是回归问题。比如：
- 这个手术需要多少小时； 
- 在未来6小时，这个镇会有多少降雨量。

### 分类
虽然回归模型可以很好地解决“有多少”的问题，但是很多问题并非如此。 例如，一家银行希望在其移动应用程序中添加支票扫描功能。 具体地说，这款应用程序
能够自动理解从图像中看到的文本，并将手写字符映射到对应的已知字符之上。 这种“哪一个”的问题叫做分类（classification）问题。 分类问题希望模型能
够预测样本属于哪个类别（category，正式称为类（class））。 例如，手写数字可能有10类，标签被设置为数字0～9。 最简单的分类问题是只有两类，这被
称之为二项分类（binomial classification）。 例如，数据集可能由动物图像组成，标签可能是猫狗两类。 

回归是训练一个回归函数来输出一个数值；分类是训练一个分类器来输出预测的类别。当有两个以上的类别时，我们把这个问题称为
多项分类（multiclass classification）问题。 常见的例子包括手写字符识别。与解决回归问题不同，分类问题的常见损失函数被称为交叉熵（cross-entropy）

### 标记问题
有些分类问题很适合于二项分类或多项分类，但是无论模型有多精确，当分类器遇到新的动物时可能会束手无策。因此我们学习预测不相互排斥的类别的问题称为
多标签分类（multi-label classification）。 举个例子，人们在技术博客上贴的标签，比如“机器学习”“技术”“小工具”“编程语言”“Linux”“云计算”
“AWS”。 一篇典型的文章可能会用5～10个标签，因为这些概念是相互关联的。 关于“云计算”的帖子可能会提到“AWS”，而关于“机器学习”的帖子也可能涉及
“编程语言”。
